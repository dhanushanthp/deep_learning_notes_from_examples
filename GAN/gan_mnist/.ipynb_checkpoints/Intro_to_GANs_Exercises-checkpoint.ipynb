{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Generative Adversarial Network\n",
    "\n",
    "In this notebook, we'll be building a generative adversarial network (GAN) trained on the MNIST dataset. From this, we'll be able to generate new handwritten digits!\n",
    "\n",
    "GANs were [first reported on](https://arxiv.org/abs/1406.2661) in 2014 from Ian Goodfellow and others in Yoshua Bengio's lab. Since then, GANs have exploded in popularity. Here are a few examples to check out:\n",
    "\n",
    "* [Pix2Pix](https://affinelayer.com/pixsrv/) \n",
    "* [CycleGAN](https://github.com/junyanz/CycleGAN)\n",
    "* [A whole list](https://github.com/wiseodd/generative-models)\n",
    "\n",
    "The idea behind GANs is that we have two networks, a generator $G$ and a discriminator $D$, competing against each other. The generator makes fake data to pass to the discriminator. The discriminator also sees real data and predicts if the data it's received is real or fake. The generator is trained to fool the discriminator, it wants to output data that looks _as close as possible_ to real data. And the discriminator is trained to figure out which data is real and which is fake. What ends up happening is that the generator learns to make data that is indistiguishable from real data to the discriminator.\n",
    "\n",
    "![GAN diagram](assets/gan_diagram.png)\n",
    "\n",
    "The general structure of a GAN is shown in the diagram above, using MNIST images as data. The latent sample is a random vector the generator uses to contruct it's fake images. As the generator learns through training, it figures out how to map these random vectors to recognizable images that can fool the discriminator.\n",
    "\n",
    "The output of the discriminator is a sigmoid function, where 0 indicates a fake image and 1 indicates an real image. If we're interested only in generating new images, we can throw out the discriminator after training. Now, let's see how we build this thing in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model Inputs\n",
    "\n",
    "First we need to create the inputs for our graph. We need two inputs, one for the discriminator and one for the generator. Here we'll call the discriminator input `inputs_real` and the generator input `inputs_z`. We'll assign them the appropriate sizes for each of the networks.\n",
    "\n",
    ">**Exercise:** Finish the `model_inputs` function below. Create the placeholders for `inputs_real` and `inputs_z` using the input sizes `real_dim` and `z_dim` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_inputs(real_dim, z_dim):\n",
    "    inputs_real = tf.placeholder(tf.float32, (None, real_dim), name='input_real') \n",
    "    inputs_z = tf.placeholder(tf.float32, (None, z_dim), name='input_z')\n",
    "    \n",
    "    return inputs_real, inputs_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generator network\n",
    "input, z is a kind of random white noise vector that we're going to feed into the generator and the generator learns how to turn this random vector into an image in this tanh layer.\n",
    "\n",
    "ReLUs are zero. But Leaky ReLUs have some small fraction there, so like 0.01 times the value for negative numbers, and then its the same for positive numbers. And the tanh function is like a sigmoid where it squishes it, but a tanh has outputs from -1 to 1. So this means, since this is -1 to 1, is that we're actually going to have to convert our MNIST images. we're going to have to rescale them so that they're between negative 1 and 1 when we pass it to our discriminator network.\n",
    "\n",
    "\n",
    "![GAN Network](assets/gan_network.png)\n",
    "\n",
    "Here we'll build the generator network. To make this network a universal function approximator, we'll need at least one hidden layer. We should use a leaky ReLU to allow gradients to flow backwards through the layer unimpeded. A leaky ReLU is like a normal ReLU, except that there is a small non-zero output for negative input values.\n",
    "\n",
    "#### Variable Scope\n",
    "We want to name the variables in our generator, in our discriminator differently. we can do that with a name scope, but with variable scopes, we can also set it to reuse the variables. So what I mean by that is, sometimes we're going to have to create the network over again. So for example, the generator, we're going to want to train it, but we also want to sample from it. And with the discriminator, we're going to be putting in fake and real images. So when we do these different things and we're putting in fake and real images in the discriminator, we want to reuse the variables from a previous creation of the network. Cause if we don't reuse the variables, then what's going to happen when we run the function to create wer network again, it's going to create totally new variables. And we don't want to. We want to use the same variables for the fake and real input images.\n",
    "\n",
    "\n",
    "Here we need to use `tf.variable_scope` for two reasons. Firstly, we're going to make sure all the variable names start with `generator`. Similarly, we'll prepend `discriminator` to the discriminator variables. This will help out later when we're training the separate networks.\n",
    "\n",
    "We could just use `tf.name_scope` to set the names, but we also want to reuse these networks with different inputs. For the generator, we're going to train it, but also _sample from it_ as we're training and after training. The discriminator will need to share variables between the fake and real input images. So, we can use the `reuse` keyword for `tf.variable_scope` to tell TensorFlow to reuse the variables instead of creating new ones if we build the graph again.\n",
    "\n",
    "To use `tf.variable_scope`, we use a `with` statement:\n",
    "```python\n",
    "with tf.variable_scope('scope_name', reuse=False):\n",
    "    # code here\n",
    "```\n",
    "\n",
    "Here's more from [the TensorFlow documentation](https://www.tensorflow.org/programmers_guide/variable_scope#the_problem) to get another look at using `tf.variable_scope`.\n",
    "\n",
    "#### Leaky ReLU\n",
    "TensorFlow doesn't provide an operation for leaky ReLUs, so we'll need to make one . For this we can just take the outputs from a linear fully connected layer and pass them to `tf.maximum`. Typically, a parameter `alpha` sets the magnitude of the output for negative values. So, the output for negative input (`x`) values is `alpha*x`, and the output for positive `x` is `x`:\n",
    "$$\n",
    "f(x) = max(\\alpha * x, x)\n",
    "$$\n",
    "\n",
    "we're going to set max, alpha times x and x. So here, alpha is just some kind of scaling parameter-- it sets the magnitude of the output for the negative values. Typically, we have this pretty small, like, 0.01. So what this is going to do is that when x is negative, we're going to take this value, because it's going to be larger than this, and then when x is positive, we're going to take x, because it's going to be larger than this part. \n",
    "\n",
    "#### Tanh Output\n",
    "The generator has been found to perform the best with $tanh$ for the generator output. This means that we'll have to rescale the MNIST images to be between -1 and 1, instead of 0 and 1. We are going to want to output the tanh to get our new images. But we also need to return the logits so that we can pass it to sigmoid across entropy with logits.\n",
    "\n",
    "And finally, we need the tanh output on the generator.\n",
    ">**Exercise:** Implement the generator network in the function below. we'll need to return the tanh output. Make sure to wrap wer code in a variable scope, with 'generator' as the scope name, and pass the `reuse` keyword argument from the function to `tf.variable_scope`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generator(z, out_dim, n_units=128, reuse=False, alpha=0.01):\n",
    "    ''' Build the generator network.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        z : Input tensor for the generator\n",
    "        out_dim : Shape of the generator output\n",
    "        n_units : Number of neurons in hidden layer\n",
    "        reuse : Reuse the variables with tf.variable_scope\n",
    "        alpha : leak parameter for leaky ReLU\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out: \n",
    "    '''\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # Hidden layer\n",
    "        h1 = tf.layers.dense(z, n_units, activation=None)\n",
    "        # Leaky ReLU\n",
    "        h1 = tf.maximum(alpha * h1, h1)\n",
    "        \n",
    "        # Logits and tanh output\n",
    "        logits = tf.layers.dense(h1, out_dim, activation=None)\n",
    "        out = tf.tanh(logits)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Discriminator\n",
    "\n",
    "The discriminator network is almost exactly the same as the generator network, except that we're using a sigmoid output layer.\n",
    "\n",
    ">**Exercise:** Implement the discriminator network in the function below. Same as above, we'll need to return both the logits and the sigmoid output. Make sure to wrap wer code in a variable scope, with 'discriminator' as the scope name, and pass the `reuse` keyword argument from the function arguments to `tf.variable_scope`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x, n_units=128, reuse=False, alpha=0.01):\n",
    "    ''' Build the discriminator network.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        x : Input tensor for the discriminator\n",
    "        n_units: Number of units in hidden layer\n",
    "        reuse : Reuse the variables with tf.variable_scope\n",
    "        alpha : leak parameter for leaky ReLU\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out, logits: \n",
    "    '''\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # Hidden layer\n",
    "        h1 = tf.layers.dense(x, n_units, activation=None)\n",
    "        # Leaky ReLU\n",
    "        h1 = tf.maximum(alpha * h1, h1)\n",
    "        \n",
    "        logits = tf.layers.dense(h1, 1, activation=None)\n",
    "        out = tf.sigmoid(logits)\n",
    "        \n",
    "        return out, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`z_size`, This is the size of the latent vector that we're putting into the generator. So again, this is just gonna be kind of randomly generated noise that we pass into the generator and then it makes images from that. And these two set the size of the hidden layers in the generator and discriminator. \n",
    "\n",
    "So one thing to remember is that when we're working with neural networks, if we have a nonlinear hidden layer in wer network, then it can be a universal function approximator. So that's why we're using hidden layers with nonlinear activations, the leaky reLUs. \n",
    "\n",
    "And speaking of leaky reLUs, this is the leak factor, so alpha, and we can pass these to the generator and discriminator networks. And this is a parameter for label smoothing in which we'll get to next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Size of input image to discriminator\n",
    "input_size = 784 # 28x28 MNIST images flattened\n",
    "# Size of latent vector to generator\n",
    "z_size = 100\n",
    "# Sizes of hidden layers in generator and discriminator\n",
    "g_hidden_size = 128\n",
    "d_hidden_size = 128\n",
    "# Leak factor for leaky ReLU\n",
    "alpha = 0.01\n",
    "# Label smoothing \n",
    "smooth = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build network\n",
    "\n",
    "Now we're building the network from the functions defined above.\n",
    "\n",
    "First is to get our inputs, `input_real, input_z` from `model_inputs` using the sizes of the input and z.\n",
    "\n",
    "Then, we'll create the generator, `generator(input_z, input_size)`. This builds the generator with the appropriate input and output sizes.\n",
    "\n",
    "Then the discriminators. We'll build two of them, one for real data and one for fake data. Since we want the weights to be the same for both real and fake data, we need to reuse the variables. For the fake data, we're getting it from the generator as `g_model`. So the real data discriminator is `discriminator(input_real)` while the fake discriminator is `discriminator(g_model, reuse=True)`.\n",
    "\n",
    ">**Exercise:** Build the network from the functions we defined earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here is where we're going to build the network from the previous functions. So we're going to get,\n",
    "* the input for the real images \n",
    "* the input for the latent vectors \n",
    "\n",
    "from the model input's function and then we're gonna create the generator network and the discriminator network. So here, we'll use the generator function to get the output, so generator `g_model` here is the output, and then we get the logits from the generator. And then here is the discriminator, `d_model_real`, so this is the output from the discriminator for real images and the logits for real images, and then here is wer output for fake images and wer logits for fake images. So remember that we're getting our fake images from a generator, so that is g_model here, so we want to pass our fake images into the discriminator and get our output from that, so that's what `d_model` is. So here, we're gonna use wer discriminator function and pass in `g_model`. And since we want to use the same weights for the real images and the fake images, we need to set reuse to True. So here we would do something like `discriminator(g_model, reuse=True)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# Create our input placeholders\n",
    "input_real, input_z = model_inputs(input_size, z_size)\n",
    "\n",
    "# Generator network here\n",
    "# G model is the changed output from our generator, and this is the logits\n",
    "g_model, g_logits = generator(input_z, input_size, n_units=g_hidden_size, alpha=alpha)\n",
    "# g_model is the generator output\n",
    "\n",
    "# Disriminator network output\n",
    "d_model_real, d_logits_real = discriminator(input_real, n_units=d_hidden_size, alpha=alpha)\n",
    "d_model_fake, d_logits_fake = discriminator(g_model, reuse=True, n_units=d_hidden_size, alpha=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Discriminator and Generator Losses\n",
    "\n",
    "We train the discriminator and generator networks at the same time. So we need losses for both of the different networks.\n",
    "\n",
    " \n",
    "Now we need to calculate the losses, which is a little tricky. For the discriminator, the total loss is the sum of the losses for real and fake images, `d_loss = d_loss_real + d_loss_fake`. The losses will by sigmoid cross-entropies, which we can get with `tf.nn.sigmoid_cross_entropy_with_logits`. We'll also wrap that in `tf.reduce_mean` to get the mean for all the images in the batch. So the losses will look something like \n",
    "\n",
    "```python\n",
    "tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "```\n",
    "\n",
    "For the real image logits, we'll use `d_logits_real` which we got from the discriminator in the cell above. For the labels, we want them to be all ones, since these are all real images. To help the discriminator generalize better, the labels are reduced a bit from 1.0 to 0.9, for example,  using the parameter `smooth`. This is known as label smoothing, typically used with classifiers to improve performance. In TensorFlow, it looks something like `labels = tf.ones_like(tensor) * (1 - smooth)`\n",
    "\n",
    "The discriminator loss for the fake data is similar. The logits are `d_logits_fake`, which we got from passing the generator output to the discriminator. These fake logits are used with labels of all zeros. Remember that we want the discriminator to output 1 for real images and 0 for fake images, so we need to set up the losses to reflect that.\n",
    "\n",
    "Finally, the generator losses are using `d_logits_fake`, the fake image logits. But, now the labels are all ones. The generator is trying to fool the discriminator, so it wants to discriminator to output ones for fake images.\n",
    "\n",
    ">**Exercise:** Calculate the losses for the discriminator and the generator. There are two discriminator losses, one for real images and one for fake images. For the real image loss, use the real logits and (smoothed) labels of ones. For the fake image loss, use the fake logits with labels of all zeros. The total discriminator loss is the sum of those two losses. Finally, the generator loss again uses the fake logits from the discriminator, but this time the labels are all ones because the generator wants to fool the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculate losses\n",
    "d_loss_real = tf.reduce_mean(\n",
    "                  tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, \n",
    "                                                          labels=tf.ones_like(d_logits_real) * (1 - smooth)))\n",
    "d_loss_fake = tf.reduce_mean(\n",
    "                  tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, \n",
    "                                                          labels=tf.zeros_like(d_logits_real)))\n",
    "d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "g_loss = tf.reduce_mean(\n",
    "             tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                     labels=tf.ones_like(d_logits_fake)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Optimizers\n",
    "we're going to be using an adam optimizer here because it works really well. So what we're doing here is we're actually going to be training the generator in discriminator variables separately\n",
    "\n",
    "\n",
    "We want to update the generator and discriminator variables separately. So we need to get the variables for each part and build optimizers for the two parts. To get all the trainable variables, we use `tf.trainable_variables()`. This creates a list of all the variables objects we've defined in our graph. Later we can iterate through it and do things to those variable objects.\n",
    "\n",
    "For the generator optimizer, we only want to generator variables.as you might remember, we used the variable scope to name all of our generator variables that, so they start with the word generator. So we can iterate through these lists that we got from trainable variables and we can create a new list that only has the variables that start with `generator`. So, we just need to iterate through the list from `tf.trainable_variables()` and keep variables that start with `generator`. Each variable object has an attribute `name` which holds the name of the variable as a string (`var.name == 'weights_0'` for instance). And that way we can have only trainable variables, that are in the generator graph and we can pass that to our atom optimizer so that we're only training those variables with the generator laws.\n",
    "\n",
    "We can do something similar with the discriminator. All the variables in the discriminator start with `discriminator`.\n",
    "\n",
    "Then, in the optimizer we pass the variable lists to the `var_list` keyword argument of the `minimize` method. This tells the optimizer to only update the listed variables. Something like `tf.train.AdamOptimizer().minimize(loss, var_list=var_list)` will only train the variables in `var_list`. you can pass in a list of variables and only those variables are going to be updated during the training.\n",
    "\n",
    ">**Exercise: ** Below, implement the optimizers for the generator and discriminator. First we'll need to get a list of trainable variables, then split that list into two lists, one for the generator variables and another for the discriminator variables. Finally, using `AdamOptimizer`, create an optimizer for each network that update the network variables separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "learning_rate = 0.002\n",
    "\n",
    "# Get the trainable_variables, split into G and D parts\n",
    "t_vars = tf.trainable_variables()\n",
    "g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "\n",
    "d_train_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "g_train_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are doing a loop through our epochs. And then inside of this loop, we are starting a loop through our batches. So we can get our batches through `mnist.train.next_batch`. So the batch is a tuple and the first element is our images and the second element is the labels, but we don't really care about the labels, so we're just going to get the images. \n",
    "\n",
    "\n",
    "since we're using the tanh output on the generator, that means that the images from the generator are scaled from -1 to +1. \n",
    "\n",
    "\n",
    "The MNIST images are actually from 0 to 1, so we have to do this rescaling. So here I'm using batch images times 2 minus 1, and that rescales the images going into the discriminator.\n",
    "\n",
    "\n",
    "our z's, our latent vectors that are going into the generator. So it's just random noise from -1 to 1, and just creating a batch size and the z size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100... Discriminator Loss: 0.3968... Generator Loss: 2.9774\n",
      "Epoch 2/100... Discriminator Loss: 0.3506... Generator Loss: 4.3563\n",
      "Epoch 3/100... Discriminator Loss: 0.3993... Generator Loss: 3.5280\n",
      "Epoch 4/100... Discriminator Loss: 0.4715... Generator Loss: 3.7795\n",
      "Epoch 5/100... Discriminator Loss: 0.6914... Generator Loss: 3.0944\n",
      "Epoch 6/100... Discriminator Loss: 0.6173... Generator Loss: 4.7404\n",
      "Epoch 7/100... Discriminator Loss: 1.1020... Generator Loss: 3.8393\n",
      "Epoch 8/100... Discriminator Loss: 0.9667... Generator Loss: 1.3836\n",
      "Epoch 9/100... Discriminator Loss: 2.1756... Generator Loss: 1.7195\n",
      "Epoch 10/100... Discriminator Loss: 1.3486... Generator Loss: 2.7166\n",
      "Epoch 11/100... Discriminator Loss: 0.7848... Generator Loss: 3.2271\n",
      "Epoch 12/100... Discriminator Loss: 0.8922... Generator Loss: 2.0358\n",
      "Epoch 13/100... Discriminator Loss: 1.3544... Generator Loss: 1.8341\n",
      "Epoch 14/100... Discriminator Loss: 1.4755... Generator Loss: 3.4732\n",
      "Epoch 15/100... Discriminator Loss: 0.9007... Generator Loss: 2.0471\n",
      "Epoch 16/100... Discriminator Loss: 1.0223... Generator Loss: 2.0372\n",
      "Epoch 17/100... Discriminator Loss: 1.6465... Generator Loss: 2.3296\n",
      "Epoch 18/100... Discriminator Loss: 1.3259... Generator Loss: 1.5975\n",
      "Epoch 19/100... Discriminator Loss: 0.9020... Generator Loss: 2.5845\n",
      "Epoch 20/100... Discriminator Loss: 0.7593... Generator Loss: 3.4942\n",
      "Epoch 21/100... Discriminator Loss: 0.8909... Generator Loss: 2.1925\n",
      "Epoch 22/100... Discriminator Loss: 1.3199... Generator Loss: 1.8280\n",
      "Epoch 23/100... Discriminator Loss: 0.7469... Generator Loss: 2.8460\n",
      "Epoch 24/100... Discriminator Loss: 0.8140... Generator Loss: 3.3158\n",
      "Epoch 25/100... Discriminator Loss: 1.0131... Generator Loss: 2.0788\n",
      "Epoch 26/100... Discriminator Loss: 0.8503... Generator Loss: 2.1621\n",
      "Epoch 27/100... Discriminator Loss: 0.8244... Generator Loss: 2.2730\n",
      "Epoch 28/100... Discriminator Loss: 0.8207... Generator Loss: 2.4510\n",
      "Epoch 29/100... Discriminator Loss: 0.8345... Generator Loss: 2.2447\n",
      "Epoch 30/100... Discriminator Loss: 0.9537... Generator Loss: 2.2295\n",
      "Epoch 31/100... Discriminator Loss: 0.7280... Generator Loss: 2.6740\n",
      "Epoch 32/100... Discriminator Loss: 0.7163... Generator Loss: 2.3631\n",
      "Epoch 33/100... Discriminator Loss: 0.7286... Generator Loss: 3.1105\n",
      "Epoch 34/100... Discriminator Loss: 0.7207... Generator Loss: 2.6462\n",
      "Epoch 35/100... Discriminator Loss: 0.7799... Generator Loss: 2.5607\n",
      "Epoch 36/100... Discriminator Loss: 0.8470... Generator Loss: 2.3967\n",
      "Epoch 37/100... Discriminator Loss: 1.0244... Generator Loss: 2.3737\n",
      "Epoch 38/100... Discriminator Loss: 0.9105... Generator Loss: 2.0553\n",
      "Epoch 39/100... Discriminator Loss: 0.8062... Generator Loss: 2.8809\n",
      "Epoch 40/100... Discriminator Loss: 1.0439... Generator Loss: 1.8622\n",
      "Epoch 41/100... Discriminator Loss: 1.1263... Generator Loss: 2.7498\n",
      "Epoch 42/100... Discriminator Loss: 0.9873... Generator Loss: 2.1169\n",
      "Epoch 43/100... Discriminator Loss: 0.9532... Generator Loss: 2.7228\n",
      "Epoch 44/100... Discriminator Loss: 0.7479... Generator Loss: 2.5852\n",
      "Epoch 45/100... Discriminator Loss: 0.8539... Generator Loss: 2.2909\n",
      "Epoch 46/100... Discriminator Loss: 0.9497... Generator Loss: 2.1776\n",
      "Epoch 47/100... Discriminator Loss: 1.0082... Generator Loss: 1.4471\n",
      "Epoch 48/100... Discriminator Loss: 0.9310... Generator Loss: 2.3519\n",
      "Epoch 49/100... Discriminator Loss: 0.9607... Generator Loss: 2.3023\n",
      "Epoch 50/100... Discriminator Loss: 0.7499... Generator Loss: 2.7655\n",
      "Epoch 51/100... Discriminator Loss: 0.6667... Generator Loss: 2.6476\n",
      "Epoch 52/100... Discriminator Loss: 0.9738... Generator Loss: 1.9190\n",
      "Epoch 53/100... Discriminator Loss: 0.7755... Generator Loss: 2.3315\n",
      "Epoch 54/100... Discriminator Loss: 0.8830... Generator Loss: 2.2114\n",
      "Epoch 55/100... Discriminator Loss: 0.9048... Generator Loss: 2.0946\n",
      "Epoch 56/100... Discriminator Loss: 0.9605... Generator Loss: 1.9721\n",
      "Epoch 57/100... Discriminator Loss: 0.8059... Generator Loss: 2.6671\n",
      "Epoch 58/100... Discriminator Loss: 0.9175... Generator Loss: 2.3157\n",
      "Epoch 59/100... Discriminator Loss: 0.8623... Generator Loss: 2.5683\n",
      "Epoch 60/100... Discriminator Loss: 0.7673... Generator Loss: 2.4490\n",
      "Epoch 61/100... Discriminator Loss: 0.9521... Generator Loss: 2.0481\n",
      "Epoch 62/100... Discriminator Loss: 0.8607... Generator Loss: 1.9192\n",
      "Epoch 63/100... Discriminator Loss: 0.8505... Generator Loss: 1.7376\n",
      "Epoch 64/100... Discriminator Loss: 0.7290... Generator Loss: 2.9810\n",
      "Epoch 65/100... Discriminator Loss: 0.8401... Generator Loss: 2.4928\n",
      "Epoch 66/100... Discriminator Loss: 0.9729... Generator Loss: 1.6466\n",
      "Epoch 67/100... Discriminator Loss: 0.9293... Generator Loss: 2.2873\n",
      "Epoch 68/100... Discriminator Loss: 0.8963... Generator Loss: 1.9202\n",
      "Epoch 69/100... Discriminator Loss: 0.7784... Generator Loss: 2.1184\n",
      "Epoch 70/100... Discriminator Loss: 0.8734... Generator Loss: 2.5422\n",
      "Epoch 71/100... Discriminator Loss: 1.0307... Generator Loss: 1.5180\n",
      "Epoch 72/100... Discriminator Loss: 0.8815... Generator Loss: 2.2873\n",
      "Epoch 73/100... Discriminator Loss: 1.0381... Generator Loss: 1.6907\n",
      "Epoch 74/100... Discriminator Loss: 1.0199... Generator Loss: 2.0689\n",
      "Epoch 75/100... Discriminator Loss: 0.9377... Generator Loss: 1.9017\n",
      "Epoch 76/100... Discriminator Loss: 0.7802... Generator Loss: 2.7070\n",
      "Epoch 77/100... Discriminator Loss: 0.7939... Generator Loss: 2.4677\n",
      "Epoch 78/100... Discriminator Loss: 1.0528... Generator Loss: 1.5803\n",
      "Epoch 79/100... Discriminator Loss: 0.9645... Generator Loss: 2.1821\n",
      "Epoch 80/100... Discriminator Loss: 0.7739... Generator Loss: 2.2475\n",
      "Epoch 81/100... Discriminator Loss: 0.9663... Generator Loss: 2.2028\n",
      "Epoch 82/100... Discriminator Loss: 1.2025... Generator Loss: 2.0935\n",
      "Epoch 83/100... Discriminator Loss: 0.9754... Generator Loss: 1.8836\n",
      "Epoch 84/100... Discriminator Loss: 0.8200... Generator Loss: 2.0316\n",
      "Epoch 85/100... Discriminator Loss: 1.0485... Generator Loss: 2.3420\n",
      "Epoch 86/100... Discriminator Loss: 0.9667... Generator Loss: 1.9279\n",
      "Epoch 87/100... Discriminator Loss: 0.8387... Generator Loss: 1.7857\n",
      "Epoch 88/100... Discriminator Loss: 0.9337... Generator Loss: 1.8740\n",
      "Epoch 89/100... Discriminator Loss: 0.8093... Generator Loss: 2.4084\n",
      "Epoch 90/100... Discriminator Loss: 0.8690... Generator Loss: 1.9551\n",
      "Epoch 91/100... Discriminator Loss: 0.8831... Generator Loss: 2.1883\n",
      "Epoch 92/100... Discriminator Loss: 0.9753... Generator Loss: 1.6095\n",
      "Epoch 93/100... Discriminator Loss: 1.0028... Generator Loss: 1.9566\n",
      "Epoch 94/100... Discriminator Loss: 0.8732... Generator Loss: 2.0260\n",
      "Epoch 95/100... Discriminator Loss: 0.9723... Generator Loss: 2.3435\n",
      "Epoch 96/100... Discriminator Loss: 0.9841... Generator Loss: 2.2685\n",
      "Epoch 97/100... Discriminator Loss: 1.3040... Generator Loss: 1.2124\n",
      "Epoch 98/100... Discriminator Loss: 0.9387... Generator Loss: 1.9237\n",
      "Epoch 99/100... Discriminator Loss: 1.0687... Generator Loss: 2.0256\n",
      "Epoch 100/100... Discriminator Loss: 0.9640... Generator Loss: 1.4761\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 100\n",
    "samples = []\n",
    "losses = []\n",
    "# Only save generator variables\n",
    "saver = tf.train.Saver(var_list=g_vars)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        for ii in range(mnist.train.num_examples//batch_size):\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Get images, reshape and rescale to pass to D\n",
    "            batch_images = batch[0].reshape((batch_size, 784))\n",
    "            batch_images = batch_images*2 - 1\n",
    "            \n",
    "            # Sample random noise for G\n",
    "            batch_z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
    "            \n",
    "            # Run optimizers\n",
    "            _ = sess.run(d_train_opt, feed_dict={input_real: batch_images, input_z: batch_z})\n",
    "            _ = sess.run(g_train_opt, feed_dict={input_z: batch_z})\n",
    "        \n",
    "        # At the end of each epoch, get the losses and print them out\n",
    "        train_loss_d = sess.run(d_loss, {input_z: batch_z, input_real: batch_images})\n",
    "        train_loss_g = g_loss.eval({input_z: batch_z})\n",
    "            \n",
    "        print(\"Epoch {}/{}...\".format(e+1, epochs),\n",
    "              \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n",
    "              \"Generator Loss: {:.4f}\".format(train_loss_g))    \n",
    "        # Save losses to view after training\n",
    "        losses.append((train_loss_d, train_loss_g))\n",
    "        \n",
    "        # Sample from generator as we're training for viewing afterwards\n",
    "        sample_z = np.random.uniform(-1, 1, size=(16, z_size))\n",
    "        gen_samples = sess.run(\n",
    "                       generator(input_z, input_size, n_units=g_hidden_size, reuse=True, alpha=alpha),\n",
    "                       feed_dict={input_z: sample_z})\n",
    "        samples.append(gen_samples)\n",
    "        saver.save(sess, './checkpoints/generator.ckpt')\n",
    "\n",
    "# Save training generator samples\n",
    "with open('train_samples.pkl', 'wb') as f:\n",
    "    pkl.dump(samples, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training loss\n",
    "\n",
    "Here we'll check out the training losses for the generator and discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x123ab2a58>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c008d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "losses = np.array(losses)\n",
    "plt.plot(losses.T[0], label='Discriminator')\n",
    "plt.plot(losses.T[1], label='Generator')\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generator samples from training\n",
    "\n",
    "Here we can view samples of images from the generator. First we'll look at images taken while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def view_samples(epoch, samples):\n",
    "    fig, axes = plt.subplots(figsize=(7,7), nrows=4, ncols=4, sharey=True, sharex=True)\n",
    "    for ax, img in zip(axes.flatten(), samples[epoch]):\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        im = ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load samples from generator taken while training\n",
    "with open('train_samples.pkl', 'rb') as f:\n",
    "    samples = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "These are samples from the final training epoch. we can see the generator is able to reproduce numbers like 5, 7, 3, 0, 9. Since this is just a sample, it isn't representative of the full range of images this generator can make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 12544 into shape (28,28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-7a5bc1916cf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mview_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-36be4b0762b1>\u001b[0m in \u001b[0;36mview_samples\u001b[0;34m(epoch, samples)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greys_r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 12544 into shape (28,28)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAboAAAGfCAYAAAAplhcAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJKlpBp0kqWkGnSSpaQadJKlp/x+uK6Fc+Oya4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b458b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = view_samples(-1, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Below I'm showing the generated images as the network was training, every 10 epochs. With bonus optical illusion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rows, cols = 10, 6\n",
    "fig, axes = plt.subplots(figsize=(7,12), nrows=rows, ncols=cols, sharex=True, sharey=True)\n",
    "\n",
    "for sample, ax_row in zip(samples[::int(len(samples)/rows)], axes):\n",
    "    for img, ax in zip(sample[::int(len(sample)/cols)], ax_row):\n",
    "        ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It starts out as all noise. Then it learns to make only the center white and the rest black. we can start to see some number like structures appear out of the noise. Looks like 1, 9, and 8 show up first. Then, it learns 5 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sampling from the generator\n",
    "\n",
    "We can also get completely new images from the generator by using the checkpoint we saved after training. We just need to pass in a new latent vector $z$ and we'll get new samples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(var_list=g_vars)\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    sample_z = np.random.uniform(-1, 1, size=(16, z_size))\n",
    "    gen_samples = sess.run(\n",
    "                   generator(input_z, input_size, n_units=g_hidden_size, reuse=True, alpha=alpha),\n",
    "                   feed_dict={input_z: sample_z})\n",
    "view_samples(0, [gen_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:dlnd]",
   "language": "python",
   "name": "conda-env-dlnd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
